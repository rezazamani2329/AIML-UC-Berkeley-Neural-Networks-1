{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a13a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run on TensorFlow 2.x\n",
    "# %tensorflow_version 2.x\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b3e236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import relevant modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# The following lines adjust the granularity of reporting. \n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "\n",
    "# The following line improves formatting when ouputting NumPy arrays.\n",
    "np.set_printoptions(linewidth = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = {0:'black', 1:'red', 2:'blue'}\n",
    "def plot_region(model,dlim,features=[]):\n",
    "    d1lim = dlim[:2]\n",
    "    d2lim = dlim[2:]\n",
    "    d1_grid, d2_grid = np.meshgrid(np.arange(d1lim[0], d1lim[1], 0.02), np.arange(d2lim[0], d2lim[1], 0.02))\n",
    "    X0 = d1_grid.ravel()\n",
    "    X1 = d2_grid.ravel()\n",
    "    \n",
    "    d12_array = np.empty((len(X0),2+len(features)))\n",
    "    d12_array[:,0] = X0\n",
    "    d12_array[:,1] = X1\n",
    "    i=2\n",
    "\n",
    "    for feature in features:\n",
    "        d12_array[:,i] = feature(X0,X1)\n",
    "        i += 1\n",
    "    \n",
    "    y_array = model.predict(d12_array)\n",
    "    y_grid = y_array.reshape(d1_grid.shape)\n",
    "    plt.contourf(d1_grid, d2_grid, y_grid, cmap='Pastel2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af641a",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "`tf.keras` provides a set of convenience functions for loading well-known datasets. Each of these convenience functions does the following:\n",
    "\n",
    "* Loads both the training set and the test set.\n",
    "* Separates each set into features and labels.\n",
    "\n",
    "The relevant convenience function for MNIST is called `mnist.load_data()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4937590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088f0c3",
   "metadata": {},
   "source": [
    "Notice that `mnist.load_data()` returned four separate values:\n",
    "\n",
    "* `x_train` contains the training set's features.\n",
    "* `y_train` contains the training set's labels.\n",
    "* `x_test` contains the test set's features.\n",
    "* `y_test` contains the test set's labels.\n",
    "\n",
    "**Note:** The MNIST .csv training set is already shuffled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a7ce2",
   "metadata": {},
   "source": [
    "## View the dataset\n",
    "\n",
    "The .csv file for the California Housing Dataset contains column names (for example, `latitude`, `longitude`, `population`). By contrast, the .csv file for MNIST does not contain column names. Instead of column names, you use ordinal numbers to access different subsets of the MNIST dataset. In fact, it is probably best to think of `x_train` and `x_test` as three-dimensional NumPy arrays:  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ea6108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 127, 100, 156, 239, 224, 177, 213, 159,  70,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 110, 250, 254, 254, 254, 254, 254, 254, 254, 254, 184,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 216, 254, 254, 254, 254, 254, 254, 254, 254, 254, 251,  54,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   3, 131, 197,  68, 137, 101,  83,  41,  70, 221, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 254, 216,  11,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 254, 254,  24,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  83, 247, 254, 192,  10,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37, 124, 254, 254, 250,  47,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 113, 178, 250, 254, 254, 254, 252, 178, 128,  50,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  69, 252, 254, 254, 254, 254, 254, 254, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 252, 254, 241, 241, 254, 247, 252, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  68,  82,   5,   5,  82,  37,  65, 167, 254, 190,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 162, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 172, 253,  75,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102, 254, 152,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38, 230, 216,  20,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  71, 222, 254, 142,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  66, 254, 254, 157,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   4,  34,  34,  78, 161, 226, 249, 254, 154,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  96, 184, 254, 254, 254, 254, 254, 249,  93,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output example #2917 of the training set.\n",
    "x_train[2917]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a557353",
   "metadata": {},
   "source": [
    "Alternatively, you can call `matplotlib.pyplot.imshow` to interpret the preceding numeric array as an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "305f6fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdda0124a00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use false colors to visualize the array.\n",
    "plt.imshow(x_train[2917])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb63c643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 254, 216,  11,   0,   0,   0,   0,   0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output row #10 of example #2917.\n",
    "x_train[2917][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c83a559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output pixel #16 of row #10 of example #2900.\n",
    "x_train[2917][10][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cfd603",
   "metadata": {},
   "source": [
    "## Task 1: Normalize feature values\n",
    "\n",
    "Complete the following code cell to map each feature value from its current representation (an integer between 0 and 255) to a floating-point value between 0 and 1.0. Store the floating-point values in `x_train_normalized` and `x_test_normalized`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3207671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.         0.         0.55294118 1.         0.66666667 0.11372549 0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "#@title Double-click to see a solution to Task 1. \n",
    "\n",
    "x_train_normalized = x_train / 255.0\n",
    "x_test_normalized = x_test / 255.0\n",
    "print(x_train_normalized[2900][10]) # Output a normalized row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7aa86c",
   "metadata": {},
   "source": [
    "## Define a plotting function\n",
    "\n",
    "The following function plots an accuracy curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b236e1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the plot_curve function.\n"
     ]
    }
   ],
   "source": [
    "#@title Define the plotting function\n",
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
    "  # list_of_metrics should be one of the names shown in:\n",
    "  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics  \n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Value\")\n",
    "\n",
    "  for m in list_of_metrics:\n",
    "    x = hist[m]\n",
    "    plt.plot(epochs[1:], x[1:], label=m)\n",
    "\n",
    "  plt.legend()\n",
    "\n",
    "print(\"Loaded the plot_curve function.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c553a2",
   "metadata": {},
   "source": [
    "\n",
    "#@title Define the plotting function\n",
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
    "  # list_of_metrics should be one of the names shown in:\n",
    "  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics  \n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Value\")\n",
    "\n",
    "  for m in list_of_metrics:\n",
    "    x = hist[m]\n",
    "    plt.plot(epochs[1:], x[1:], label=m)\n",
    "\n",
    "  plt.legend()\n",
    "\n",
    "print(\"Loaded the plot_curve function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "398bcd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate):\n",
    "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
    "  \n",
    "  # All models in this course are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # The features are stored in a two-dimensional 28X28 array. \n",
    "  # Flatten that two-dimensional array into a a one-dimensional \n",
    "  # 784-element array.\n",
    "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Define the first hidden layer.   \n",
    "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "  \n",
    "  # Define a dropout regularization layer. \n",
    "  model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "  # Define the output layer. The units parameter is set to 10 because\n",
    "  # the model must choose among 10 possible output values (representing\n",
    "  # the digits from 0 to 9, inclusive).\n",
    "  #\n",
    "  # Don't change this layer.\n",
    "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
    "                           \n",
    "  # Construct the layers into a model that TensorFlow can execute.  \n",
    "  # Notice that the loss function for multi-class classification\n",
    "  # is different than the loss function for binary classification.  \n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model    \n",
    "\n",
    "\n",
    "def train_model(model, train_features, train_label, epochs,\n",
    "                batch_size=None, validation_split=0.1):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, \n",
    "                      validation_split=validation_split)\n",
    " \n",
    "  # To track the progression of training, gather a snapshot\n",
    "  # of the model's metrics at each epoch. \n",
    "  epochs = history.epoch\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  return epochs, hist    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6158ad5f",
   "metadata": {},
   "source": [
    "## Invoke the previous functions\n",
    "\n",
    "Run the following code cell to invoke the preceding functions and actually train the model on the training set. \n",
    "\n",
    "**Note:** Due to several factors (for example, more examples and a more complex neural network) training MNIST might take longer than training the California Housing Dataset. Be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d6bf6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 12:38:04.568155: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-16 12:38:04.712979: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-11-16 12:38:04.731204: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3498265000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 40ms/step - loss: 2.0700 - accuracy: 0.3060 - val_loss: 1.1454 - val_accuracy: 0.6843\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.1107 - accuracy: 0.6551 - val_loss: 0.6022 - val_accuracy: 0.8552\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.7258 - accuracy: 0.7798 - val_loss: 0.4367 - val_accuracy: 0.8884\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.5735 - accuracy: 0.8295 - val_loss: 0.3755 - val_accuracy: 0.8992\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4995 - accuracy: 0.8515 - val_loss: 0.3368 - val_accuracy: 0.9070\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4540 - accuracy: 0.8647 - val_loss: 0.3129 - val_accuracy: 0.9131\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4200 - accuracy: 0.8762 - val_loss: 0.2942 - val_accuracy: 0.9163\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4090 - accuracy: 0.8764 - val_loss: 0.2814 - val_accuracy: 0.9212\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3876 - accuracy: 0.8861 - val_loss: 0.2698 - val_accuracy: 0.9227\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3713 - accuracy: 0.8899 - val_loss: 0.2604 - val_accuracy: 0.9269\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3579 - accuracy: 0.8946 - val_loss: 0.2520 - val_accuracy: 0.9293\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3482 - accuracy: 0.8971 - val_loss: 0.2440 - val_accuracy: 0.9309\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3360 - accuracy: 0.9003 - val_loss: 0.2366 - val_accuracy: 0.9321\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3251 - accuracy: 0.9051 - val_loss: 0.2313 - val_accuracy: 0.9342\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3213 - accuracy: 0.9055 - val_loss: 0.2244 - val_accuracy: 0.9356\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3074 - accuracy: 0.9083 - val_loss: 0.2186 - val_accuracy: 0.9375\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.3044 - accuracy: 0.9080 - val_loss: 0.2148 - val_accuracy: 0.9388\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2926 - accuracy: 0.9122 - val_loss: 0.2100 - val_accuracy: 0.9385\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2930 - accuracy: 0.9128 - val_loss: 0.2047 - val_accuracy: 0.9417\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2804 - accuracy: 0.9170 - val_loss: 0.2001 - val_accuracy: 0.9421\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2763 - accuracy: 0.9182 - val_loss: 0.1976 - val_accuracy: 0.9422\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2709 - accuracy: 0.9199 - val_loss: 0.1926 - val_accuracy: 0.9447\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2670 - accuracy: 0.9183 - val_loss: 0.1899 - val_accuracy: 0.9443\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2633 - accuracy: 0.9226 - val_loss: 0.1861 - val_accuracy: 0.9456\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2575 - accuracy: 0.9237 - val_loss: 0.1837 - val_accuracy: 0.9467\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2481 - accuracy: 0.9256 - val_loss: 0.1800 - val_accuracy: 0.9478\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2549 - accuracy: 0.9240 - val_loss: 0.1785 - val_accuracy: 0.9481\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2449 - accuracy: 0.9260 - val_loss: 0.1744 - val_accuracy: 0.9494\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2353 - accuracy: 0.9286 - val_loss: 0.1729 - val_accuracy: 0.9493\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2357 - accuracy: 0.9302 - val_loss: 0.1709 - val_accuracy: 0.9503\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2317 - accuracy: 0.9293 - val_loss: 0.1694 - val_accuracy: 0.9509\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2276 - accuracy: 0.9322 - val_loss: 0.1676 - val_accuracy: 0.9511\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2260 - accuracy: 0.9325 - val_loss: 0.1655 - val_accuracy: 0.9518\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2275 - accuracy: 0.9305 - val_loss: 0.1646 - val_accuracy: 0.9524\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2237 - accuracy: 0.9325 - val_loss: 0.1628 - val_accuracy: 0.9524\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2190 - accuracy: 0.9327 - val_loss: 0.1605 - val_accuracy: 0.9535\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2171 - accuracy: 0.9333 - val_loss: 0.1607 - val_accuracy: 0.9528\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2123 - accuracy: 0.9357 - val_loss: 0.1590 - val_accuracy: 0.9544\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2108 - accuracy: 0.9352 - val_loss: 0.1584 - val_accuracy: 0.9541\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2074 - accuracy: 0.9370 - val_loss: 0.1572 - val_accuracy: 0.9548\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2078 - accuracy: 0.9351 - val_loss: 0.1555 - val_accuracy: 0.9555\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2095 - accuracy: 0.9368 - val_loss: 0.1552 - val_accuracy: 0.9551\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1990 - accuracy: 0.9385 - val_loss: 0.1545 - val_accuracy: 0.9555\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2026 - accuracy: 0.9379 - val_loss: 0.1530 - val_accuracy: 0.9563\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1956 - accuracy: 0.9404 - val_loss: 0.1527 - val_accuracy: 0.9567\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1982 - accuracy: 0.9378 - val_loss: 0.1518 - val_accuracy: 0.9572\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1959 - accuracy: 0.9395 - val_loss: 0.1510 - val_accuracy: 0.9567\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1946 - accuracy: 0.9403 - val_loss: 0.1511 - val_accuracy: 0.9562\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1924 - accuracy: 0.9390 - val_loss: 0.1504 - val_accuracy: 0.9566\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1950 - accuracy: 0.9393 - val_loss: 0.1490 - val_accuracy: 0.9564\n",
      "\n",
      " Evaluate the new model against the test set:\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14665043354034424, 0.9574999809265137]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmMklEQVR4nO3deXSc9X3v8fdXo32xrc0ylmxsgzFesMGYJUCIWWMSCARKA0l6qMtyaIFLepsmKU0vzdImvSm5SQqNj9sYQhbIAm4IpQZDSQgUguXY4B2EbWx5lazN2jUz3/vHPBJjeWTLssYjaz6vc+bMzLPMfB+B5zPP7ze/32PujoiISH8ZqS5ARERGJgWEiIgkpIAQEZGEFBAiIpKQAkJERBJSQIiISEJJDQgzW2RmW8ysxsy+lGB9sZktN7O3zexNM5sTt267ma0zs7VmVp3MOkVE5HCWrHEQZhYC3gGuAmqBVcCt7r4xbptvAa3u/hUzOxN4xN2vCNZtBxa4e/1g37OsrMynTJkyfAchIjLKrV69ut7dyxOty0zi+54P1Lj7VgAzexK4HtgYt80s4BsA7r7ZzKaYWYW77xvKG06ZMoXqap1siIgMlpm9P9C6ZDYxVQI7457XBsvivQXcCGBm5wOnAlXBOgdeMLPVZnbXQG9iZneZWbWZVdfV1Q1b8SIi6S6ZAWEJlvVvz/omUGxma4H7gDVAOFh3sbvPB64B7jGzSxO9ibsvdfcF7r6gvDzhWZKIiAxBMpuYaoFJcc+rgN3xG7h7C7AYwMwM2BbccPfdwf1+M1tOrMnqlSTWKyIicZIZEKuA6WY2FdgF3AJ8On4DMxsHtLt7N3AH8Iq7t5hZAZDh7geDx1cDXx1KET09PdTW1tLZ2Xkch5K+cnNzqaqqIisrK9WliMgJlrSAcPewmd0LPA+EgGXuvsHM7g7WLwFmAo+bWYRY5/Xtwe4VwPLYSQWZwE/dfcVQ6qitraWoqIgpU6YQvJ4Mkrtz4MABamtrmTp1aqrLEZETLJlnELj7c8Bz/ZYtiXv8OjA9wX5bgXnDUUNnZ6fCYYjMjNLSUtT5L5Ke0mIktcJh6PS3E0lfST2DEBGRxCJRp7G9mwOt3Rxo7aK+LXbf0hFmXH4WpYXZlBXmBLdsxuZlYWaEI1E6w1E6eyJ0dEfoCkeIRGHGhKJhr1EBISKSRM0dPdTsb6Vm/0He3ddKTV0r7+5rZXdzB8cykUVmhmEGPZHDdyovymHV3145jFUH7znsrygpEQ6HyczUf06RwWjvDrOvpYv27jCdPRE6e6J99x09sW/lvcu6wlG6eiJ09kToiTrujjuxG07UIRp12rsjtHWHaesK09YVobUrTFt3mKb2nr73zcnMYFp5IeeeWsyNpZWUFeZQWphNaUHsLKG0MIei3EyaO3o40NpNfWtXcIudXTiQlxUiNyuD3KwQuZkhcrNDFOUk59++PlFOgBtuuIGdO3fS2dnJ/fffz1133cWKFSt44IEHiEQilJWV8dJLL9Ha2sp9991HdXU1ZsaDDz7ITTfdRGFhIa2trQD88pe/5Nlnn+Wxxx7jT//0TykpKWHNmjXMnz+fT33qU3zuc5+jo6ODvLw8Hn30UWbMmEEkEuGLX/wizz//PGbGnXfeyaxZs3j44YdZvnw5ACtXruT73/8+Tz/9dCr/VCJ9H8AZGYn7v8KRKNsPtLN5bwtb9h5k056D1Ow/SEaGUVqQTUlBNiXBB25JQTbusKupg12NHdQ2tbOrsYPGuA/twcjJjH0gZ4UMM8MAM8joe2wU5IQoyMmkIDuT8qIcCrIzKcjJpLI4j9PLC5leUUhVcT6hAY4rXm/T0gyGv9noWKRVQHzl1xvYuLtlWF9z1sQxPHjd7CNus2zZMkpKSujo6OC8887j+uuv58477+SVV15h6tSpNDQ0APC1r32NsWPHsm7dOgAaGxuP+v7vvPMOL774IqFQiJaWFl555RUyMzN58cUXeeCBB3jqqadYunQp27ZtY82aNWRmZtLQ0EBxcTH33HMPdXV1lJeX8+ijj7J48eLj/4OIDEE06qze0ciK9XtZsX4vu5o6yMnMIC87RF5WKPjWHCLqztb6NrrDUQBCGca0sgJmTxwLwIG2LrbVt1G9vZHG9m6iQWtMXlaIyuI8KsflMbdqHJXj8jhlbC752ZnkZYfIDQIgt9+385ysDHIyM9L2xxppFRCp8r3vfa/vm/rOnTtZunQpl156ad/YgpKSEgBefPFFnnzyyb79iouLj/raN998M6FQCIDm5mZuu+023n33XcyMnp6evte9++67+5qget/vT/7kT/jxj3/M4sWLef3113n88ceH6YhFjq4nEuWNrQdYsX4vL2zcR93BLrJDGXx4ehk3za+kKxxr7unojtARNPFEHT48vYwzJ4xhxoQiTh9fSG5WKOHrR6NOU0fs30Bxflbafsgfj7QKiKN900+G3/zmN7z44ou8/vrr5Ofns3DhQubNm8eWLVsO29bdE/5PHL+s/4jwgoKCvsd/93d/x2WXXcby5cvZvn07CxcuPOLrLl68mOuuu47c3Fxuvvlm9WGkEXfnDzsaqdnfSnfE6QlH6YnEbt2RWAN7cUF2Xxt5eWEOpYU5jMvLorU7zN7mTvY0d7IvuN/b0kFDWzdtXYe2w7d1h+nojvR1xnowHZs7RD3Wfp+fHeKyM8ezaPYEFs4opyh3eEbtZ2QYJQXZw/Ja6UqfCEnW3NxMcXEx+fn5bN68mTfeeIOuri5++9vfsm3btr4mppKSEq6++moefvhhvvOd7wCxJqbi4mIqKirYtGkTM2bMYPny5RQVJW6XbG5uprIyNmHuY4891rf86quvZsmSJSxcuLCviamkpISJEycyceJEvv71r7Ny5cpk/ylkBNh/sJOn/7CLn1fvZGtd24DbmZHwFzYDLS8rzKG0IJuCnBCFOZlUFOWSHzzOywrF2u2D7yi9X1UyzJg3aRwfnl424FmApJYCIskWLVrEkiVLmDt3LjNmzODCCy+kvLycpUuXcuONNxKNRhk/fjwrV67ky1/+Mvfccw9z5swhFArx4IMPcuONN/LNb36Ta6+9lkmTJjFnzpy+Duv+vvCFL3Dbbbfx7W9/m8svv7xv+R133ME777zD3LlzycrK4s477+Tee+8F4DOf+Qx1dXXMmjXrhPw9ZPh1h6O8V9fKnuYO8rMzKcrNZExuFmNysyjMzSTqzsub9/Pz6lpe3rKfSNQ5b0oxd3/kNC46rZSczBDZoQyyMzPIChmhDMMdmjp6DvsVTUNbN0W5mUwYG2vDnzAml4oxuWRnpsWY27STtCvKpcKCBQu8/wWDNm3axMyZM1NU0ch37733cs4553D77bcPuI3+hiNDZ0+EPc2dbK1rZfPeg2zee5Ate1vYWtdGODrwv+PsUAbdkSjlRTncNL+KmxdUcVp54QmsXEYyM1vt7gsSrdMZRBo799xzKSgo4KGHHkp1KUKsU3VXUwc1da28t7+VXU0d7G7qYE9zJ7ubOqhv7T5k+8pxeZw5oYgrZlZw5oQiqorz6eyJcLCzh5bOMAc7w7R09NDRE+H8KSUsnFFOZkjf9GXwFBBpbPXq1akuIS11dEfYVt/Gtvo2ttbFRtbW7G9la10bHT2Rvu0KskNMHJfHxHF5zJ44lspxuZwyNo8pZfmcUVE0bJ25IgNJi4AY6Fc8cnSjqQkyWbrDUf6wo5FV2xro6InEBk9Z0BkbDKRqaOvuC4TdzYf+Eq1yXB6njS/kgqmlnD6+sO+mn2ZKqo36gMjNzeXAgQOUlpbqH9sx6r0eRG5ubqpLGVHcnXf2tfK7d+t4taae329t6Pvmn5lheLBNfLdAUW4m08oLuWBaKVPLCphaVsC08gKmlBZQkKRpEkSO16j/P7Oqqora2lpd02CIeq8ol+7cnQ27W/hF9U6eW7+XuoNdAEwrL+CPF1RxyfRyLphWwpgEzT7RqMfOKPQFRU4yoz4gsrKydDU0OUxXOMKmPbFfAZUV5nBaeSFVxXmHdeLWt3bxH2t28cvVtWzee5DszAyunDmehWeM5+LpZVSOyzvqew00p5DISDfqA0LE3anZ38ranU28VdvE27XNbNrTcti0ydmhDKaWFXDa+AKmlRWyZd9BXt68n3DUmTdpHF+/YQ7XzZ3I2Hx1Dkt6UEDIqNXQ1s1Tq2t54s0dbK2PjRouzMlkbtVYbr9kGmdPGsuZE8ZwoK2b94Kflr5X18rG3S2sWL+XkoIc/uySqfzRuVWcUZHaWTVFUkEBIaOKu/PG1gaeeHMHK9bvpTsSZcGpxdx56TTOm1LCtLKCw5p8ppQVcO6ph06M2B2OEsqwQU3NLDJaKSDkpNcTifJ2bTP/U1PP8jW72FrfRlFuJp++YDK3nj95SJdi1NQRIgoIOQmFI1HW727h9fcO8PrWA1Rvb6C9O/Yz0/mTx/HPN8/j42edQl62JoATOR4KCBnx3J336tp4raaeV2vqeeO9AxzsCgNw+vhCbppfxYdOK+WCqSWUFuakuFqR0UMBISNOTyTK+wfaWb+rmd+9W89rNfXsbYmNPj61NJ9r503kotNKuXBaKeVFCgSRZFFASEq4O3UHu9jR0M7W+rbgV0SxqSh2NLT3zU5anJ/FRaeXcUlwm1SSn+LKRdKHAkKSqndaije3HWBbfTs7GtrY0dDOjoZ2OnuifdtlhzKYUpbPjAlFXHPWBE4rL2TGhCJmThijgWYiKaKAkGG3p7mD12oO8Oq7dbxac4D61ti0FHlZIU4tzefU0gIunV7O5NJ8JpfkM6W0gEkl+fpJqcgIo4CQYdHaFebx17fz1Opa3gsuZVlakM3FQdPQh04rpao4T/MRiZxEFBByXJo7evjh/2znB69uo7mjhw9NK+WW8yZzyfQyZlQUqXlI5CSmgJAhaWrvZtlr23n0tW0c7Axz5cwK7rv8dOZNGpfq0kRkmCggZNCiUWdtbRP/+fYefrZqJ61dYRbNnsC9l5/OnMqxqS5PRIZZUgPCzBYB3wVCwL+7+zf7rS8GlgGnAZ3An7n7+sHsKydGOBLlzW0NrNiwl+c37GVfSxdZIePq2RO47/LTOXPCmFSXKCJJkrSAMLMQ8AhwFVALrDKzZ9x9Y9xmDwBr3f2TZnZmsP0Vg9xXkqQnEuXVmnqee3sPKzfto6m9h9ysDBaeMZ5FcyZw2ZnjGZunKa9FRrtknkGcD9S4+1YAM3sSuB6I/5CfBXwDwN03m9kUM6sApg1iXxlG4UiUN7Y28Ozbu1mxYS9N7T0U5WRy5awKPjp7Ah85o1xzG4mkmWQGRCWwM+55LXBBv23eAm4EXjWz84FTgapB7guAmd0F3AUwefLkYSk8Xbg7q99vZPmaXaxYv5cDbd0UZIe4alYF186dyIfPKCMnU6Egkq6SGRCJft/o/Z5/E/iuma0F1gFrgPAg940tdF8KLAVYsGBBwm3kULubOlgeXEZzW30beVkhrpg5nmvnTmThjHJysxQKIpLcgKgFJsU9rwJ2x2/g7i3AYgCLjaDaFtzyj7avHJvOnggvbNzHL6p38mpNPe5w4bQS7rnsdK6ZM4GCHP2gTUQOlcxPhVXAdDObCuwCbgE+Hb+BmY0D2t29G7gDeMXdW8zsqPvK4P32nTq+8Mu32NfSReW4PO67fDp/NL+KyaWa+E5EBpa0gHD3sJndCzxP7Keqy9x9g5ndHaxfAswEHjezCLEO6NuPtG+yah2t2rvDfOO5zfzojfeZPr6Qh24+m4tOK9XoZhEZFHMfPc32CxYs8Orq6lSXMSKs2dHI//75W2yrb+OOS6by+Y/OUN+CiBzGzFa7+4JE69TwPMr0RKI8/N81PPxyDRVFOfz0zgu46LSyVJclIichBcQoUXewi5c37+dHb7zPul3N3HhOJQ9+YrYGtInIkCkgTlLuTs3+VlZu2seLG/exZmcT7lA5Lo9//cx8PnbWKakuUUROcgqIk9Avqnfy8Ms1vH+gHYC5VWP5yyvP4MqZFcw8pUjXXBCRYaGAOImEI1H+8bnNLHttG+dMHsedH57GFTPHc8rYvFSXJiKjkALiJNHc0cN9T6zhlXfqWHzxFP72YzPJDGWkuiwRGcUUECeBbfVt3P7DVew40M43bjyLW8/XnFMiknwKiBHutZp6/uInfyDD4Md3XMCF00pTXZKIpAkFxAgVjkT54evv84/PbWJaWQE/uO08TY0hIieUAmKEiUad/1q/l4dWbmFrXRuXnzme795yNkW5Gs8gIieWAmKEcHdeebeebz2/mfW7Wpg+vpAlnz2Xj86u0M9WRSQlFBAjwOr3G/m/Kzbz+20NVI7L46Gb53HDOZWENKmeiKSQAiLFlr26ja8+u5Gywhy+8onZ3HL+JF3FTURGBAVECj32WiwcFs2ewEN/PE8X7RGREUWfSCny+Ovb+ftfb+Sjsyv4l0+fQ5YGvYnICKNPpRT40evb+T+/2sBVsyr4l1vnKxxEZETSJ9MJ9uM33ufvfrWBK2eO55FPzyc7U/8JRGRk0qfTCfTT3+/gy/+xnivOHM8jn1E4iMjIpk+oE+RXa3fxwPJ1XDajnH/97Hz9UklERjwFxAnQ1N7N3z+zgXNPLeb7nz1X4SAiJwUFxAnwnRffpbmjh6/fMIfcLIWDiJwcFBBJtmXvQX70xvt8+oLJzDxlTKrLEREZNAVEErk7X312A4U5mfzVVTNSXY6IyDFRQCTRCxv38VrNAf7yyukUF2SnuhwRkWOigEiSzp4IX//PjZxRUchnLzw11eWIiBwzTbWRJD94dRs7Gzr4yR0X6NrRInJS0idXEuxt7uSRl2v46OwKLj69LNXliIgMiQIiCf5pxWbCUedvPzYr1aWIiAyZAmKYrX6/keVrdnHnh6fqGtIiclJTQAwjd+drz26kYkwOf7Hw9FSXIyJyXJIaEGa2yMy2mFmNmX0pwfqxZvZrM3vLzDaY2eK4ddvNbJ2ZrTWz6mTWOVzerm1m7c4m7r18ui7+IyInvaR9iplZCHgEuAqoBVaZ2TPuvjFus3uAje5+nZmVA1vM7Cfu3h2sv8zd65NV43B7ctVO8rJC3HD2xFSXIiJy3JJ5BnE+UOPuW4MP/CeB6/tt40CRmRlQCDQA4STWlDRtXWGeWbuLj889haLcrFSXIyJy3JIZEJXAzrjntcGyeA8DM4HdwDrgfnePBusceMHMVpvZXQO9iZndZWbVZlZdV1c3fNUfo/9ct4e27gi3nDcpZTWIiAynZAaEJVjm/Z5/FFgLTATOBh42s94Z7S529/nANcA9ZnZpojdx96XuvsDdF5SXlw9L4UPxs1U7Oa28gHNPLU5ZDSIiwymZAVELxH+driJ2phBvMfC0x9QA24AzAdx9d3C/H1hOrMlqRHp330FWv9/ILedNJtZaJiJy8ktmQKwCppvZVDPLBm4Bnum3zQ7gCgAzqwBmAFvNrMDMioLlBcDVwPok1npcfrZqJ1kh45Pz+7egiYicvJL2KyZ3D5vZvcDzQAhY5u4bzOzuYP0S4GvAY2a2jliT1Bfdvd7MpgHLg2/jmcBP3X1Fsmo9Hl3hCE+v2cVVsyooK8xJdTkiIsMmqT/Wd/fngOf6LVsS93g3sbOD/vttBeYls7bhsnLjPhrauvnUeZNTXYqIyLDSSOrj9LNVO6kcl8clmpRPREYZBcRx2NnQzu/erefmBVWEMtQ5LSKjiwLiOPyieidmcPMCjX0QkdFHATFEkajz8+paLp1eTuW4vFSXIyIy7BQQQ/TKO3XsbenUyGkRGbUUEEP05KodlBZkc8XMilSXIiKSFAqIIag72MVLm/Zz07lVZGfqTygio5M+3Ybg1Zo6wlHnE/M0rbeIjF4KiCF4u7aZ3KwMzpxQlOpSRESSRgExBOt3NTN74lgyQ/rzicjopU+4YxSJOut3tXBW5dhUlyIiklSDDohgVtW0915dKx09EQWEiIx6Rw0IM7vIzDYCm4Ln88zsX5Ne2Qi1rrYZgLOqFBAiMroN5gzi/xG78tsBAHd/C0h4dbd0sG5XM3lZIU4rL0x1KSIiSTWoJiZ339lvUSQJtZwU1u1qZvbEMZqcT0RGvcEExE4zuwhwM8s2s88TNDelm3AkyobdzWpeEpG0MJiAuBu4B6gkdp3ps4Pnaee9ujY6e6LMVUCISBo46hXl3L0e+MwJqGXEe7u2CUC/YBKRtHDUgDCzRwHvv9zd/ywpFY1g63Y1U5AdYmqZOqhFZPQbzDWpn417nAt8EtidnHJGtnXBCGp1UItIOhhME9NT8c/N7AngxaRVNEKFI1E27m7hsxeemupSREROiKFMtTEdmDzchYx07+5vpSusDmoRSR+D6YM4SKwPwoL7vcAXk1zXiNM7gnqOOqhFJE0MpolJc1oT638ozMlkaqmmpBKR9DBgQJjZ/CPt6O5/GP5yRq63gxHUGeqgFpE0caQziIeOsM6By4e5lhGrJxJl054WbvuQOqhFJH0MGBDuftmJLGQke2ffQbrDUc6qGpfqUkRETpjBjIPAzOYAs4iNgwDA3R9PVlEjTd8U3+qgFpE0MphfMT0ILCQWEM8B1wCvAukTELuaKcrN5NSS/FSXIiJywgxmHMQfAVcAe919MTAPyElqVSPMul3NzJk4Vh3UIpJWBhMQne4eBcJmNgbYD0wbzIub2SIz22JmNWb2pQTrx5rZr83sLTPbYGaLB7vvidIdjrJ5z0ENkBORtDNgQJjZw2Z2MfCmmY0D/g1YDfwBePNoL2xmIeARYk1Ss4BbzWxWv83uATa6+zxizVgPBdecGMy+J8Q7+w7SHYlqgJyIpJ0j9UG8C/wzMBFoBZ4ArgLGuPvbg3jt84Ead98KYGZPAtcDG+O2caDIzAwoBBqAMHDBIPY9Id4OOqh1BiEi6WbAMwh3/667f4jY9acbgEeB/wJuMLPpg3jtSiD+UqW1wbJ4DwMzic0Ouw64P2jOGsy+AJjZXWZWbWbVdXV1gyjr2Kzb1cyY3Ewmq4NaRNLMUfsg3P19d/8ndz8H+DSx6b43D+K1E/Xo9r+uxEeBtcTOUs4GHg76OQazb299S919gbsvKC8vH0RZx2bdribOqhpL7CRHRCR9HDUgzCzLzK4zs58QO4N4B7hpEK9dC0yKe17F4deRWAw87TE1wDbgzEHum3Rd4Qhb9h7krMpxJ/qtRURS7khzMV0F3Ap8nFin9JPAXe7eNsjXXgVMN7OpwC7gFmJnIPF2EPsJ7e/MrAKYAWwFmgaxb9Jt2XuQnohrgJyIpKUjdVI/APwU+Ly7NxzrC7t72MzuBZ4HQsAyd99gZncH65cAXwMeM7N1xJqVvhhcA5tE+x5rDcdr3S51UItI+krqXEzu/hyx0dfxy5bEPd4NXD3YfU+0DbtbGJuXRVVxXirLEBFJiaFcUS5t1B3s4pSxueqgFpG0pIA4gqb2borzs1NdhohISiggjqChrZuSAgWEiKQnBcQRNLb3MC4/K9VliIikhAJiANGo09SuMwgRSV8KiAG0dPYQddQHISJpSwExgIa2bgCdQYhI2lJADKCxPRYQ6oMQkXSlgBhAQ1sPoDMIEUlfCogB9J5BqA9CRNKVAmIAjeqDEJE0p4AYQEN7N9mhDPKzQ6kuRUQkJRQQA2hq66G4IEvzMIlI2lJADKBB8zCJSJpTQAygsU0BISLpTQExgAZNsyEiaU4BMYCm9lgfhIhIulJAJBDpnahPTUwiksYUEAm0dMQm6hungBCRNKaASKChXYPkREQUEAk09U6zoYAQkTSmgEigb6I+NTGJSBpTQCTQOw+TpvoWkXSmgEigUX0QIiIKiEQa2rvJztREfSKS3hQQCcSm2dBEfSKS3hQQCTS09WgeJhFJewqIBJo0D5OIiAIikYb2bo2BEJG0p4BIoLcPQkQknSkg+olEnaaOHg2SE5G0l9SAMLNFZrbFzGrM7EsJ1v+1ma0NbuvNLGJmJcG67Wa2LlhXncw647V09OCuaTZERDKT9cJmFgIeAa4CaoFVZvaMu2/s3cbdvwV8K9j+OuAv3b0h7mUuc/f6ZNWYiCbqExGJSeYZxPlAjbtvdfdu4Eng+iNsfyvwRBLrGZQPptlQQIhIektmQFQCO+Oe1wbLDmNm+cAi4Km4xQ68YGarzeyugd7EzO4ys2ozq66rqzvuohvbNVGfiAgkNyASDUP2Aba9DnitX/PSxe4+H7gGuMfMLk20o7svdfcF7r6gvLz8+CrmgzMIXW5URNJdMgOiFpgU97wK2D3AtrfQr3nJ3XcH9/uB5cSarJKutw9CI6lFJN0lMyBWAdPNbKqZZRMLgWf6b2RmY4GPAL+KW1ZgZkW9j4GrgfVJrLVPY5sm6hMRgST+isndw2Z2L/A8EAKWufsGM7s7WL8k2PSTwAvu3ha3ewWwPJgsLxP4qbuvSFat8RrbuynJz9ZEfSKS9pIWEADu/hzwXL9lS/o9fwx4rN+yrcC8ZNY2kIa2Ho2BEBFBI6kP09iuaTZEREABcZjGNk3UJyICCojD9PZBiIikOwVEnN6J+nQGISKigDhEc+9EfeqDEBFRQMRraNNEfSIivRQQcZo0ilpEpI8CIk7vGYQCQkREAXGIxnZN1Cci0ksBEadvqm/1QYiIKCDiNbZ1k5OZQV6WJuoTEVFAxGlo66ZYE/WJiAAKiEM0tmuaDRGRXgqIOI3tPZSog1pEBFBAHKIxaGISEREFxCEa2hUQIiK9FBCBSNRp1kR9IiJ9FBCB3on6SjRRn4gIoIDo0zfNhs4gREQABUSfRk3UJyJyCAVEoFFTfYuIHEIBEfhgoj4FhIgIKCD6NLTFJurT1eRERGIUEIHGdk3UJyISTwERaGzrpqRAE/WJiPRSQAQaNYpaROQQCohAQ1u3riQnIhJHARFobO/RGYSISBwFRKCxvVtjIERE4igggHAkGpuoT2cQIiJ9khoQZrbIzLaYWY2ZfSnB+r82s7XBbb2ZRcysZDD7Dqfeifo0BkJE5ANJCwgzCwGPANcAs4BbzWxW/Dbu/i13P9vdzwb+BvituzcMZt/hpFHUIiKHS+YZxPlAjbtvdfdu4Eng+iNsfyvwxBD3PS6N7bFR1OqDEBH5QDIDohLYGfe8Nlh2GDPLBxYBTw1h37vMrNrMquvq6oZUaN9U3+qDEBHpk8yASDQk2QfY9jrgNXdvONZ93X2puy9w9wXl5eVDKPODmVzVxCQi8oFkBkQtMCnueRWwe4Btb+GD5qVj3fe49TUx6QxCRKRPMgNiFTDdzKaaWTaxEHim/0ZmNhb4CPCrY913uDS2d5OblUFetibqExHplZmsF3b3sJndCzwPhIBl7r7BzO4O1i8JNv0k8IK7tx1t32TV2tCmeZhERPpLWkAAuPtzwHP9li3p9/wx4LHB7JssjQoIEZHDaCQ1mmZDRCQRBQTBRH0KCBGRQygg6O2D0DQbIiLx0j4g3J3LZpRz9qRxqS5FRGRESWon9cnAzPjOLeekugwRkREn7c8gREQkMQWEiIgkpIAQEZGEFBAiIpKQAkJERBJSQIiISEIKCBERSUgBISIiCZn7QBd5O/mYWR3w/hE2KQPqT1A5I1E6H386Hzuk9/Hr2I/sVHdPeDnOURUQR2Nm1e6+INV1pEo6H386Hzuk9/Hr2Id+7GpiEhGRhBQQIiKSULoFxNJUF5Bi6Xz86XzskN7Hr2MforTqgxARkcFLtzMIEREZJAWEiIgklDYBYWaLzGyLmdWY2ZdSXU+ymdkyM9tvZuvjlpWY2Uozeze4L05ljcliZpPM7GUz22RmG8zs/mD5qD9+M8s1szfN7K3g2L8SLB/1x97LzEJmtsbMng2ep9OxbzezdWa21syqg2VDPv60CAgzCwGPANcAs4BbzWxWaqtKuseARf2WfQl4yd2nAy8Fz0ejMPBX7j4TuBC4J/jvnQ7H3wVc7u7zgLOBRWZ2Ielx7L3uBzbFPU+nYwe4zN3Pjhv/MOTjT4uAAM4Hatx9q7t3A08C16e4pqRy91eAhn6Lrwd+GDz+IXDDiazpRHH3Pe7+h+DxQWIfFpWkwfF7TGvwNCu4OWlw7ABmVgV8HPj3uMVpcexHMOTjT5eAqAR2xj2vDZalmwp33wOxD1FgfIrrSTozmwKcA/yeNDn+oIllLbAfWOnuaXPswHeALwDRuGXpcuwQ+zLwgpmtNrO7gmVDPv7MJBQ4ElmCZfp97yhnZoXAU8Dn3L3FLNH/BqOPu0eAs81sHLDczOakuKQTwsyuBfa7+2ozW5jiclLlYnffbWbjgZVmtvl4XixdziBqgUlxz6uA3SmqJZX2mdkpAMH9/hTXkzRmlkUsHH7i7k8Hi9Pm+AHcvQn4DbG+qHQ49ouBT5jZdmLNyJeb2Y9Jj2MHwN13B/f7geXEmteHfPzpEhCrgOlmNtXMsoFbgGdSXFMqPAPcFjy+DfhVCmtJGoudKvwA2OTu345bNeqP38zKgzMHzCwPuBLYTBocu7v/jbtXufsUYv/G/9vdP0saHDuAmRWYWVHvY+BqYD3HcfxpM5LazD5GrH0yBCxz939IbUXJZWZPAAuJTfe7D3gQ+A/g58BkYAdws7v378g+6ZnZJcDvgHV80Bb9ALF+iFF9/GY2l1hHZIjYF8Cfu/tXzayUUX7s8YImps+7+7XpcuxmNo3YWQPEug9+6u7/cDzHnzYBISIixyZdmphEROQYKSBERCQhBYSIiCSkgBARkYQUECIikpACQuQYmFkkmCmz9zZsE7+Z2ZT42XdFUi1dptoQGS4d7n52qosQORF0BiEyDIJ5+P8puBbDm2Z2erD8VDN7yczeDu4nB8srzGx5cN2Gt8zsouClQmb2b8G1HF4IRkOLpIQCQuTY5PVrYvpU3LoWdz8feJjYqH2Cx4+7+1zgJ8D3guXfA34bXLdhPrAhWD4deMTdZwNNwE1JPRqRI9BIapFjYGat7l6YYPl2Yhfq2RpMFLjX3UvNrB44xd17guV73L3MzOqAKnfvinuNKcSm554ePP8ikOXuXz8BhyZyGJ1BiAwfH+DxQNsk0hX3OIL6CSWFFBAiw+dTcfevB4//h9jMogCfAV4NHr8E/Dn0XeBnzIkqUmSw9O1E5NjkBVdr67XC3Xt/6ppjZr8n9sXr1mDZ/wKWmdlfA3XA4mD5/cBSM7ud2JnCnwN7kl28yLFQH4TIMAj6IBa4e32qaxEZLmpiEhGRhHQGISIiCekMQkREElJAiIhIQgoIERFJSAEhIiIJKSBERCSh/w/UGL63tYtFWQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "batch_size = 4000\n",
    "validation_split = 0.2\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate)\n",
    "\n",
    "# Train the model on the normalized training set.\n",
    "epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
    "                           epochs, batch_size, validation_split)\n",
    "\n",
    "# Plot a graph of the metric vs. epochs.\n",
    "list_of_metrics_to_plot = ['accuracy']\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
    "\n",
    "# Evaluate against the test set.\n",
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1306fef6",
   "metadata": {},
   "source": [
    "## Task 2: Optimize the model\n",
    "\n",
    "Experiment with the following:\n",
    "\n",
    "* number of hidden layers \n",
    "* number of nodes in each layer\n",
    "* dropout regularization rate\n",
    "\n",
    "What trends did you discover?  Can you reach at least 98% accuracy against the test set? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a0cc458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Double-click to view some possible answers.\n",
    "\n",
    "# It would take much too long to experiment \n",
    "# fully with topography and dropout regularization \n",
    "# rate. In the real world, you would\n",
    "# also experiment with learning rate, batch size, \n",
    "# and number of epochs.  Since you only have a \n",
    "# few minutes, searching for trends can be helpful.\n",
    "# Here is what we discovered:\n",
    "#   * Adding more nodes (at least until 256 nodes) \n",
    "#     to the first hidden layer improved accuracy.\n",
    "#   * Adding a second hidden layer generally \n",
    "#     improved accuracy.\n",
    "#   * When the model contains a lot of nodes, \n",
    "#     the model overfits unless the dropout rate \n",
    "#     is at least 0.5. \n",
    "\n",
    "# We reached 98% test accuracy with the \n",
    "# following configuration:\n",
    "#   * One hidden layer of 256 nodes; no second \n",
    "#     hidden layer.\n",
    "#   * dropout regularization rate of 0.4\n",
    "\n",
    "# We reached 98.2% test accuracy with the \n",
    "# following configuration:\n",
    "#   * First hidden layer of 256 nodes; \n",
    "#     second hidden layer of 128 nodes.\n",
    "#   * dropout regularization rate of 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7653ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6529c06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f675fd87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
